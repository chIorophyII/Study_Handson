{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c04a14",
   "metadata": {},
   "source": [
    "# 3. 고전적인 퍼셉트론(퍼셉트론 훈련 알고리즘으로 훈련된 단일 TLU)보다 로지스틱 회귀 분류기를 일반적으로 선호하는 이유? 퍼셉트론을 어떻게 수정하면 로지스틱 회귀 분류기와 동등하게 만들 수 있을까?\n",
    "> 고전적인 퍼셉트론은 데이터셋이 선형적으로 구분될 때만 수렴하고 클래스 확률을 추정할 수 없음  \n",
    "\n",
    "> 로지스틱 회귀 분류기는 데이터셋이 선형적으로 구분되지 못해도 좋은 솔루션으로 수렴하고 클래스 확률을 출력  \n",
    "\n",
    "> 퍼셉트론의 활성화 함수를 로지스틱 활성화 함수로(여러 개 뉴런일 경우 소프트웨어 활성화 함수로) 바꾸고, 경사 하강법을 사용해(또는 크로스 엔트로피) 훈련시키면 로지스틱 회귀 분류기와 동일하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40729a7f",
   "metadata": {},
   "source": [
    "# 4. 왜 초창기의 다층 퍼셉트론을 훈련할 때 로지스틱 활성화 함수가 핵심 요소였나?\n",
    "> 로지스틱 활성화 함수의 도함수는 어디에서나 0이 아니어서 경사 하강법이 항상 경사를 따라 이동할 수 있으므로 초창기 MLP의 핵심 요소였음. 활성화 함수가 계단 함수일 때는 경사가 없기 때문에 경사 하강법이 이동할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd8082",
   "metadata": {},
   "source": [
    "# 5. 인기 많은 활성화 함수 세 가지는 무엇일까?\n",
    "> 계단 함수, 로지스틱 함수(시그모이드), 하이퍼볼릭 탄젠트 함수, ReLU 함수 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24570fd1",
   "metadata": {},
   "source": [
    "# 6. 통과 뉴런 10개로 구성된 입력층, 뉴런 50개로 구성된 은닉층, 뉴런 3개로 구성된 출력층으로 이루어진 다층 퍼셉트론이 있다고 가정, 모든 뉴런은 ReLU 활성화 함수를 사용\n",
    "## 입력행렬 $X$의 크기는? \n",
    "> $m$(훈련 배치의 크기) x $10$\n",
    "\n",
    "## 은닉층의 가중치 벡터 $W_h$와 편향 벡터 $b_h$의 크기는?\n",
    "> $W_h$의 크기는 10 x 50, $b_h$의 길이는 50\n",
    "\n",
    "## 출력층의 가중치 벡터 $W_o$와 편향 벡터 $b_o$의 크기는?\n",
    "> $W_o$의 크기는 50 x 3, $b_o$의 길이는 3\n",
    "\n",
    "## 네트위크의 출력 행렬 $Y$의 크기는?\n",
    "> 출력 행렬 $Y$의 크기는 $m$ x $3$\n",
    "\n",
    "## $X, W_h, b_h, W_o, b_o$의 함수로 네트워크 출력 행렬 $Y$를 계산하는 식\n",
    "> $Y$ = ReLU(ReLU($XW_h + b_h)W_o + b_o$)  \n",
    "\n",
    "> ReLU 함수는 행렬에 있는 음수를 무조건 0으로 만듦. 편향 벡터를 행렬에 더하면 행렬의 모든 행에 덧셈이 각기 적용되는 **브로트캐스팅**이 일어남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5d974",
   "metadata": {},
   "source": [
    "# 7. \n",
    "## 스팸 메일을 분류하기 위해 출력층에 몇 개의 뉴런이 필요할까? \n",
    "> 스팸 메일을 분류하기 위해서는 신경망의 출력층에 하나의 뉴런만 필요함. 예를 들어 이메일이 스팸일 확률을 출력\n",
    "\n",
    "## 출력층에 어떤 활성화 함수를 사용해야할까? \n",
    "> 확률을 추정할 때 일반적으로 출력층에 로지스틱 활성화 함수를 사용\n",
    "\n",
    "## MNIST문제라면 출력층에 어떤 활성화 함수를 사용하고, 뉴런은 몇 개가 필요한가?\n",
    "> MNIST 문제라면 출력층에 10개의 뉴런이 필요하고, 다중 클래스 환경에서 클래스마다 하나의 확률을 출력하기 위해 로지스틱 함수를 소프트맥스 활성화 함수로 바꾸어야 함.\n",
    "\n",
    "## 2장에서 본 주택 가격 예측용 네트워크에 대해서는?\n",
    "> 주택 가격을 예측하는 신경망을 만들고 싶다면 출력층에 활성화 함수가 없는 출력 뉴런 하나가 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c0a97",
   "metadata": {},
   "source": [
    "# 8. 역전파란 무엇이고 어떻게 작동하나? 역전파와 후진 모드 자동 미분의 차이점은?\n",
    "> 역전파는 인공 신경망을 훈련시키는 하나의 기법. 먼저 모델의 모든 파라미터(모든 가중치와 편향)에 대한 비용 함수의 그래디언트를 계산하고, 이 그래디언트를 사용해 경사하강법 스텝을 수행함.  \n",
    "\n",
    "> 역전파 단계는 모델 파라미터가 비용 함수를 최소화하는 값으로 수렴할 때까지 훈련배치에서 일반적으로 수천 혹은 수백만번 수행됨. 그래디언트를 계산하기 위해 역전파는 후진 자동 미분을 사용  \n",
    "\n",
    "> 후진 모드 자동 미분은 계산 그래프의 정방향 계산에서 현재 훈련 배치에 대한 모든 노드의 값을 구한 후 역방향 계산에서 한번에 모든 그래디언트를 구함  \n",
    "\n",
    "> 역전파는 그래디언트 계산과 경사 하강법 스텝을 여러 번 수행해 인공 신경망을 훈련시키는 전체 프로세스를 의미  \n",
    "> 후진 모드 자동 미분은 그래디언트를 효과적으로 계산하는 하나의 기법으로 역전파에서 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e96665",
   "metadata": {},
   "source": [
    "# 9. 다층 퍼셉트론에서 조정할 수 있는 하이퍼파라미터를 모두 나열. 훈련 데이터에 다층 퍼셉트론이 과대적합되었다면 이를 해결하기 위해 하이퍼파라미터를 어떻게 조정해야 할까?\n",
    "> 기본 MLP에서 바꿀 수 있는 하이퍼파라미터는 **은닉층 수, 각 은닉층의 뉴런 수, 각 은닉층과 출력층에서 사용하는 활성화 함수**  \n",
    "\n",
    "> 일반적으로 ReLU가 은닉층의 활성화 함수 기본값으로 좋음  \n",
    "\n",
    "> 출력층에서는 일반적으로 이진분류에서는 로지스틱 활성화 함수, 다중 분류에서는 소프트맥스 활성화 함수를 사용하고, 회귀에서는 활성화 함수를 적용하지 않음  \n",
    "\n",
    "> MLP가 과대적합 되었아면 은닉층 수와 각 은닉층에 있는 뉴런 수를 줄여볼 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
